{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bf9e57f2",
   "metadata": {},
   "source": [
    "# Data Scarping on HKJC\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e20b32e6",
   "metadata": {},
   "source": [
    "## Get date from hkjc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7da03b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome()\n",
    "\n",
    "time.sleep(2)\n",
    "\n",
    "\n",
    "# try:\n",
    "time.sleep(0.5)\n",
    "driver.get(f\"https://racing.hkjc.com/racing/information/English/Racing/LocalResults.aspx\")\n",
    "select = Select(driver.find_element(By.ID, 'selectId'))\n",
    "\n",
    "# Collect the values or visible text of all options\n",
    "dates_extract = [option.text for option in select.options]\n",
    "\n",
    "driver.quit()\n",
    "\n",
    "dates_extract=set(dates_extract)\n",
    "date_diff=dates_extract\n",
    "\n",
    "try:\n",
    "    with open(\"date_list.txt\", \"r\") as file:\n",
    "        lines = file.readlines()\n",
    "        dates_old=[line.strip(\"\\n\") for line in lines]\n",
    "        dates_old=set(dates_old)\n",
    "        date_diff=dates_extract.difference(dates_old)\n",
    "        date_diff=sorted(date_diff, key=lambda x: datetime.strptime(x, '%d/%m/%Y'),reverse=True)\n",
    "    print(\"Records of date found in your storage, new dates will update to [date_list.txt]\")\n",
    "    os.remove('date_list.txt')\n",
    "except:\n",
    "    print(\"no records of date exist in your storage\")\n",
    "    pass\n",
    "\n",
    "dates_extract=sorted(dates_extract, key=lambda x: datetime.strptime(x, '%d/%m/%Y'),reverse=True)\n",
    "\n",
    "for i in dates_extract:\n",
    "    with open(\"date_list.txt\", \"a\") as f:\n",
    "        f.write(i+\"\\n\")\n",
    "\n",
    "if len(date_diff)==0:\n",
    "    print(\"No date need to be added\")\n",
    "else:\n",
    "    print(\"Date extracted successfully from HKJC, stored to file name: [date_list.txt]\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1bbe4f5",
   "metadata": {},
   "source": [
    "## Get links from race record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cb55203",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if old URLS exists\n",
    "try:\n",
    "    old_link=np.loadtxt(\"link.txt\", delimiter=\",\",dtype=str)\n",
    "    old_link = [re.sub(r'^[\\{\\s\\'\"]+|[\\}\\s\\'\"]+$', \"\", url) for url in old_link]\n",
    "    os.remove(\"link.txt\")\n",
    "except:\n",
    "    old_link=np.array([])\n",
    "\n",
    "# Initialize the Chrome driver\n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "links_new = []\n",
    "for Date in date_diff:\n",
    "    for race in range(1, 13):  # extract 1-12 races\n",
    "        try:\n",
    "            time.sleep(0.5)\n",
    "            driver.get(f\"https://racing.hkjc.com/racing/information/English/Racing/LocalResults.aspx?RaceDate={Date}&RaceNo={race}\")\n",
    "\n",
    "            # Wait until the table is present\n",
    "            WebDriverWait(driver, 1).until(\n",
    "                EC.presence_of_element_located((By.XPATH, '//*[@id=\"innerContent\"]/div[2]/div[5]/table'))\n",
    "            )\n",
    "\n",
    "            race_table = driver.find_element(By.XPATH, '//*[@id=\"innerContent\"]/div[2]/div[5]/table')\n",
    "            rows = race_table.find_elements(By.TAG_NAME, 'tr')\n",
    "\n",
    "            # Loop through each row to extract links\n",
    "            for row in rows:\n",
    "                # Find all anchor tags within the row\n",
    "                anchors = row.find_elements(By.TAG_NAME, 'a')\n",
    "                for anchor in anchors:\n",
    "                    # Get the href attribute\n",
    "                    link = anchor.get_attribute('href')\n",
    "                    if link[-4:] !=\".jpg\":\n",
    "                        links_new.append(link)\n",
    "\n",
    "        except Exception as e:\n",
    "            continue\n",
    "\n",
    "# Close the driver after finishing the scraping\n",
    "driver.quit()\n",
    "\n",
    "links_new = [re.sub(r'^[\\{\\s\\'\"]+|[\\}\\s\\'\"]+$', \"\", url) for url in links_new]\n",
    "\n",
    "#combine old links and new links\n",
    "save_link=(set(old_link) | set(links_new))\n",
    "\n",
    "#Update the links record\n",
    "with open(\"link.txt\", \"w\") as file:\n",
    "   file.write(str(save_link))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b8a48ce",
   "metadata": {},
   "source": [
    "## Grouping URLS by Horse Jockey and Trianer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d7bc177",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize lists to store full URLs\n",
    "horse_urls = []\n",
    "trainer_urls = []\n",
    "jockey_urls = []\n",
    "\n",
    "# Regular expressions to find IDs\n",
    "horse_pattern = re.compile(r'HorseId=([^&]+)')\n",
    "trainer_pattern = re.compile(r'TrainerId=([^&]+)')\n",
    "jockey_pattern = re.compile(r'JockeyId=([^&]+)')\n",
    "\n",
    "# Iterate through URLs and categorize them\n",
    "for url in links_new:\n",
    "    if horse_pattern.search(url):\n",
    "        horse_urls.append(url)\n",
    "    elif trainer_pattern.search(url):\n",
    "        trainer_urls.append(url)\n",
    "    elif jockey_pattern.search(url):\n",
    "        jockey_urls.append(url)\n",
    "        \n",
    "horse_urls=set(horse_urls)\n",
    "trainer_urls=set(trainer_urls)\n",
    "jockey_urls=set(jockey_urls)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e3530dc",
   "metadata": {},
   "source": [
    "## Get Horse Record be each horse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "703a16d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver2 = webdriver.Chrome()\n",
    "\n",
    "#Extract old record if exists\n",
    "try:\n",
    "    horseRecorddf=pd.read_csv('horseRecord.csv')\n",
    "    horseRecorddf=horseRecorddf.reset_index(drop=True)\n",
    "    print(\"Horse record found, updating record to [horseRecord.csv]\")\n",
    "except:\n",
    "    print(\"Getting Horse Record, Record will be save into [horseRecord.csv]\")\n",
    "    horseRecorddf=pd.DataFrame()\n",
    "    \n",
    "for i in horse_urls:    \n",
    "    try:\n",
    "\n",
    "            time.sleep(1)\n",
    "            driver2.get(i)\n",
    "\n",
    "            name = driver2.find_element(By.XPATH, '//*[@id=\"innerContent\"]/div[2]/div[1]/table[1]/tbody/tr/td[1]/table/tbody/tr[1]/td/span')\n",
    "\n",
    "\n",
    "            for idx in [3,4,5]:\n",
    "                table_xpath = f'//*[@id=\"innerContent\"]/div[2]/div[1]/table[{idx}]'\n",
    "                try:\n",
    "                    table_element = driver2.find_element(By.XPATH, table_xpath)\n",
    "                    table_html = table_element.get_attribute('outerHTML')\n",
    "                    df_list = pd.read_html(table_html)\n",
    "                    race_record_df = df_list[0]\n",
    "                    # Check for the \"Race Index\" column which is present in the English site\n",
    "                    if \"Race Index\" in race_record_df.iloc[0,0]:\n",
    "                        horsedf=race_record_df\n",
    "                        break\n",
    "                except Exception as e:\n",
    "                    continue\n",
    "\n",
    "            # Use XPath to find the <td> elements\n",
    "            td_elements = driver2.find_elements(By.XPATH, '//*[@id=\"innerContent\"]/div[2]/div[1]/table[1]/tbody/tr/td[2]/table/tbody/tr/td')\n",
    "\n",
    "            # Extract the text from the first <td> elements\n",
    "            results = [td.text for td in td_elements]\n",
    "            # Extract the text\n",
    "            name_text = name.text\n",
    "\n",
    "            data_dict = {}\n",
    "            for i in range(0, len(results), 3):\n",
    "                key = results[i].strip()  # Remove any leading/trailing whitespace\n",
    "                value = results[i + 2].strip()  # Value is two indices ahead\n",
    "                data_dict[key] = value\n",
    "\n",
    "\n",
    "\n",
    "            horsedf.insert(1,\"Colour / Sex\", list(data_dict.values())[1], allow_duplicates=True)\n",
    "            horsedf.insert(1,\"Country of Origin / Age\", list(data_dict.values())[0], allow_duplicates=True)\n",
    "            horsedf.insert(1,\"HorseName\", name_text, allow_duplicates=True)\n",
    "            try:\n",
    "                horsedf.columns = horsedf.columns.astype(str)\n",
    "                horseRecorddf=pd.concat([horseRecorddf,horsedf],ignore_index=True)\n",
    "            except NameError:\n",
    "                horseRecorddf=horsedf\n",
    "\n",
    "    except:\n",
    "        continue\n",
    "\n",
    "# Close the driver after finishing the scraping\n",
    "driver2.quit()\n",
    "\n",
    "\n",
    "try:\n",
    "    os.remove('horseRecord.csv')\n",
    "    \n",
    "except FileNotFoundError:\n",
    "    pass\n",
    "\n",
    "\n",
    "\n",
    "horseRecorddf.to_csv(\"horseRecord.csv\",index=False)\n",
    "\n",
    "print(\"Horse Record have been save into [horseRecord.csv]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15bf60ad",
   "metadata": {},
   "source": [
    "# Cleaning Horse record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0fe8b21",
   "metadata": {},
   "outputs": [],
   "source": [
    "horserecord=pd.read_csv(\"horseRecord.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f5bff7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_ms(t):\n",
    "    part = t.split(\".\")\n",
    "    m = int(part[0])\n",
    "    sec = int(part[1])\n",
    "    ms = int(part[2])\n",
    "    return ((m*60*1000)+(sec*1000)+ms)/1000\n",
    "\n",
    "\n",
    "cleanedRecord = horserecord.copy()\n",
    "cleanedRecord = cleanedRecord.rename(columns=horserecord.iloc[0]).copy()\n",
    "cleanedRecord = cleanedRecord.rename(columns={cleanedRecord.columns[1]: \"HorseName\"})\n",
    "cleanedRecord = cleanedRecord.rename(columns={cleanedRecord.columns[2]: \"Country of Origin / Age\"})\n",
    "cleanedRecord = cleanedRecord.rename(columns={cleanedRecord.columns[3]: \"Colour / Sex\"})\n",
    "\n",
    "cleanedRecord = cleanedRecord.dropna(subset=['Race Index'])\n",
    "\n",
    "cleanedRecord['Pla.']=pd.to_numeric(cleanedRecord['Pla.'],errors='coerce',downcast=\"signed\")\n",
    "cleanedRecord['Dr.'] = pd.to_numeric(cleanedRecord['Dr.'],errors='coerce',downcast=\"signed\")\n",
    "cleanedRecord['Rtg.'] = pd.to_numeric(cleanedRecord['Rtg.'],errors='coerce',downcast=\"signed\")\n",
    "cleanedRecord['Act. Wt.'] = pd.to_numeric(cleanedRecord['Act. Wt.'],errors='coerce',downcast=\"signed\")\n",
    "cleanedRecord['Declar. Horse Wt.'] = pd.to_numeric(cleanedRecord['Declar. Horse Wt.'],errors='coerce')\n",
    "cleanedRecord['Win Odds'] = pd.to_numeric(cleanedRecord['Win Odds'],errors='coerce')\n",
    "cleanedRecord['Race Index']=pd.to_numeric(cleanedRecord['Race Index'],errors='coerce',downcast=\"signed\")\n",
    "\n",
    "\n",
    "cleanedRecord = cleanedRecord.dropna(subset=['Race Index'])\n",
    "cleanedRecord['Race Index'] = cleanedRecord['Race Index'].astype('str')\n",
    "cleanedRecord = cleanedRecord.dropna(subset=['Pla.'])\n",
    "# cleanedRecord = cleanedRecord.drop('Video Replay',axis=1)\n",
    "cleanedRecord = cleanedRecord[cleanedRecord['Race Class']!='GRIFFIN']\n",
    "\n",
    "\n",
    "cleanedRecord['Rtg.'] = cleanedRecord['Rtg.'].fillna(value=100)\n",
    "cleanedRecord[['RC','Track','Course']] = cleanedRecord['RC/Track/ Course'].str.split(\" / \",expand=True)\n",
    "cleanedRecord[['Country of Origin','Age']]=cleanedRecord[\"Country of Origin / Age\"].str.split(\" / \",expand=True)\n",
    "cleanedRecord['Age']=pd.to_numeric(cleanedRecord['Age'],errors='coerce',downcast=\"signed\")\n",
    "\n",
    "\n",
    "split_cs = cleanedRecord[\"Colour / Sex\"].str.split(\" / \", expand=True)\n",
    "cleanedRecord['Colour'] = split_cs[0]\n",
    "cleanedRecord['Sex'] = split_cs[1]\n",
    "\n",
    "cleanedRecord['Course']=cleanedRecord['Course'].str.replace('\"','')\n",
    "cleanedRecord['Finish Time'] = cleanedRecord['Finish Time'].apply(to_ms)\n",
    "\n",
    "\n",
    "cleanedRecord=cleanedRecord.drop_duplicates(subset=[\"HorseName\", \"Date\"])\n",
    "gamecounts = dict(cleanedRecord['HorseName'].value_counts())\n",
    "cleanedRecord['Total Raced'] = cleanedRecord['HorseName'].map(gamecounts)\n",
    "wins = cleanedRecord.groupby('HorseName')['Pla.'].apply(lambda x: (x == 1).sum())\n",
    "winrate = (wins / cleanedRecord.groupby('HorseName')['Total Raced'].first())*100\n",
    "cleanedRecord['Win Rate'] = cleanedRecord['HorseName'].map(winrate)\n",
    "\n",
    "\n",
    "cleanedRecord = cleanedRecord[cleanedRecord['Race Class']!='R']\n",
    "cleanedRecord= cleanedRecord.drop(['RC/Track/ Course','Running Position','LBW','Total Raced',\n",
    "                                   'Country of Origin / Age','Colour / Sex','Video Replay'],axis=1)\n",
    "cleanedRecord=cleanedRecord.reset_index(drop=True)\n",
    "\n",
    "\n",
    "cleanedRecord[\"Date\"]=pd.to_datetime(cleanedRecord.Date)\n",
    "cleanedRecord[\"Date\"]=cleanedRecord[\"Date\"].dt.strftime(\"%Y-%m-%d\")\n",
    "\n",
    "\n",
    "firstplace_df = cleanedRecord[cleanedRecord['Pla.'] == 1]\n",
    "\n",
    "class5=cleanedRecord[cleanedRecord[\"Race Class\"]==\"5\"]\n",
    "class4=cleanedRecord[cleanedRecord[\"Race Class\"]==\"4\"]\n",
    "class3=cleanedRecord[cleanedRecord[\"Race Class\"]==\"3\"]\n",
    "class2=cleanedRecord[cleanedRecord[\"Race Class\"]==\"2\"]\n",
    "class1=cleanedRecord[cleanedRecord[\"Race Class\"]==\"1\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c5c3c54",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleanedRecord.to_csv(\"cleanedRecord.csv\",index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
